import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # å¤šæŒ‡æ ‡è¯„ä¼°
from data_processor.DataPlot import read_stock_data  # å¤ç”¨ä½ ç°æœ‰çš„æ•°æ®è¯»å–å‡½æ•°
from strategy.StockDataset import StockDataset_binary
from strategy.Mlp import StockMLP


# ----------------------
# æ ¸å¿ƒå›æµ‹å‡½æ•°
# ----------------------
def load_pretrained_model(model_path, seq_len, num_features, device):
    """
    åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡
    å‚æ•°ï¼š
    model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚"D:\lc\githubCode\DeepQuant\output\mlp_10251430_ep500_82.50.pth"ï¼‰
    seq_len: è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    num_features: ç‰¹å¾æ•°ï¼ˆå›ºå®šä¸º5ï¼Œä¸è®­ç»ƒä¸€è‡´ï¼‰
    device: è¿è¡Œè®¾å¤‡ï¼ˆcpu/cudaï¼‰
    è¿”å›ï¼šåŠ è½½æƒé‡åçš„æ¨¡å‹
    """
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆç»“æ„ä¸è®­ç»ƒä¸€è‡´ï¼‰
    model = StockMLP(seq_len=seq_len, num_features=num_features).to(device)
    # åŠ è½½æ¨¡å‹å­—å…¸ï¼ˆå¤„ç†CPU/GPUä¸åŒ¹é…é—®é¢˜ï¼‰
    checkpoint = torch.load(model_path, map_location=device)
    # åŠ è½½æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    # åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆç¦ç”¨Dropout/BatchNormæ›´æ–°ï¼‰
    model.eval()
    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹ï¼š{model_path}")
    print(f"   æ¨¡å‹è®­ç»ƒæ—¶çš„Epochï¼š{checkpoint['epoch']}")
    print(f"   æ¨¡å‹è®­ç»ƒæ—¶çš„Val Accï¼š{checkpoint['val_acc']:.2f}%")
    return model


def backtest_model(model, test_dataset, device, threshold=0.5):
    """
    å›æµ‹æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°
    å‚æ•°ï¼š
    model: åŠ è½½å¥½çš„é¢„è®­ç»ƒæ¨¡å‹
    test_dataset: æ–°æ•°æ®çš„Datasetå®ä¾‹
    device: è¿è¡Œè®¾å¤‡
    threshold: æ¶¨è·Œåˆ¤æ–­é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰
    è¿”å›ï¼šé¢„æµ‹æ¦‚ç‡ã€é¢„æµ‹æ ‡ç­¾ã€çœŸå®æ ‡ç­¾ã€è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    model.eval()  # è¯„ä¼°æ¨¡å¼
    pred_probs = []  # é¢„æµ‹æ¦‚ç‡
    pred_labels = []  # é¢„æµ‹æ ‡ç­¾ï¼ˆ0/1ï¼‰
    true_labels = []  # çœŸå®æ ‡ç­¾ï¼ˆ0/1ï¼‰

    # æ— æ¢¯åº¦æ¨ç†ï¼ˆåŠ é€Ÿä¸”é¿å…ä¿®æ”¹æ¨¡å‹ï¼‰
    with torch.no_grad():
        for x, y in test_dataset:
            # å¢åŠ batchç»´åº¦ï¼ˆæ¨¡å‹è¾“å…¥éœ€ä¸º[batch, seq_len, num_features]ï¼‰
            x = x.unsqueeze(0).to(device)
            print(f"y={y}")
            # é¢„æµ‹æ¦‚ç‡
            prob = model(x).item()
            # è½¬æ¢ä¸ºæ ‡ç­¾
            pred_label = 1 if prob >= threshold else 0
            # æ”¶é›†ç»“æœ
            pred_probs.append(prob)
            pred_labels.append(pred_label)
            true_labels.append(int(y.item()))  # çœŸå®æ ‡ç­¾è½¬æ•´æ•°

    # è®¡ç®—å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ï¼ˆsklearnï¼‰
    metrics = {
        "accuracy": accuracy_score(true_labels, pred_labels) * 100,  # å‡†ç¡®ç‡ï¼ˆ%ï¼‰
        "precision": precision_score(true_labels, pred_labels, zero_division=0) * 100,  # ç²¾ç¡®ç‡ï¼ˆ%ï¼‰
        "recall": recall_score(true_labels, pred_labels, zero_division=0) * 100,  # å¬å›ç‡ï¼ˆ%ï¼‰
        "f1_score": f1_score(true_labels, pred_labels, zero_division=0) * 100  # F1å€¼ï¼ˆ%ï¼‰
    }

    return np.array(pred_probs), np.array(pred_labels), np.array(true_labels), metrics


def plot_backtest_result(true_labels, pred_labels, num_points=300):
    """
    ç»˜åˆ¶å›æµ‹ç»“æœå¯¹æ¯”å›¾ï¼ˆçœŸå®æ¶¨è·Œ vs é¢„æµ‹æ¶¨è·Œï¼‰
    å‚æ•°ï¼š
    true_labels: çœŸå®æ ‡ç­¾æ•°ç»„
    pred_labels: é¢„æµ‹æ ‡ç­¾æ•°ç»„
    num_points: ç»˜åˆ¶æœ€åNä¸ªç‚¹ï¼ˆé¿å…å›¾è¿‡äºæ‹¥æŒ¤ï¼‰
    """
    plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ”¯æŒ
    plt.rcParams['axes.unicode_minus'] = False  # è´Ÿå·æ˜¾ç¤º

    # å–æœ€ånum_pointsä¸ªç‚¹ï¼ˆè‹¥æ•°æ®ä¸è¶³åˆ™å–å…¨éƒ¨ï¼‰
    plot_true = true_labels[-num_points:] if len(true_labels) > num_points else true_labels
    plot_pred = pred_labels[-num_points:] if len(pred_labels) > num_points else pred_labels
    time_steps = range(len(plot_true))  # æ—¶é—´æ­¥

    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)

    # å­å›¾1ï¼šçœŸå®æ¶¨è·Œ vs é¢„æµ‹æ¶¨è·Œï¼ˆæ—¶åºå¯¹æ¯”ï¼‰
    ax1.plot(time_steps, plot_true, label='çœŸå®æ¶¨è·Œ', color='black', linewidth=2)
    ax1.plot(time_steps, plot_pred, label='é¢„æµ‹æ¶¨è·Œ', color='red', linestyle='--', linewidth=2)
    ax1.set_ylabel('æ¶¨è·Œæ ‡ç­¾ï¼ˆ0=è·Œï¼Œ1=æ¶¨ï¼‰', fontsize=12)
    ax1.set_title('å›æµ‹ï¼šçœŸå®æ¶¨è·Œ vs é¢„æµ‹æ¶¨è·Œ', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(-0.2, 1.2)  # å›ºå®šyè½´èŒƒå›´ï¼Œé¿å…æ³¢åŠ¨è¿‡å¤§

    # å­å›¾2ï¼šé¢„æµ‹æ­£ç¡®æ€§æ ‡è®°ï¼ˆç»¿è‰²=æ­£ç¡®ï¼Œçº¢è‰²=é”™è¯¯ï¼‰
    correct = (plot_true == plot_pred).astype(int)
    incorrect = (plot_true != plot_pred).astype(int)
    # æ­£ç¡®é¢„æµ‹ï¼šç”¨ç»¿è‰²ç‚¹æ ‡è®°
    ax2.scatter(
        [t for t, c in zip(time_steps, correct) if c == 1],
        [1] * sum(correct),
        color='green', label='é¢„æµ‹æ­£ç¡®', s=20, alpha=0.7
    )
    # é”™è¯¯é¢„æµ‹ï¼šç”¨çº¢è‰²ç‚¹æ ‡è®°
    ax2.scatter(
        [t for t, i in zip(time_steps, incorrect) if i == 1],
        [0] * sum(incorrect),
        color='red', label='é¢„æµ‹é”™è¯¯', s=20, alpha=0.7
    )
    ax2.set_xlabel('æ—¶é—´æ­¥', fontsize=12)
    ax2.set_ylabel('é¢„æµ‹ç»“æœ', fontsize=12)
    ax2.set_title(f'é¢„æµ‹æ­£ç¡®æ€§ï¼ˆæ­£ç¡®æ•°ï¼š{sum(correct)}ï¼Œé”™è¯¯æ•°ï¼š{sum(incorrect)}ï¼‰', fontsize=14, fontweight='bold')
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(-0.5, 1.5)
    ax2.set_yticks([0, 1])
    ax2.set_yticklabels(['é”™è¯¯', 'æ­£ç¡®'])

    plt.tight_layout()
    plt.show()


# ----------------------
# 3. å›æµ‹ä¸»é€»è¾‘ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰
# ----------------------
if __name__ == "__main__":
    # ----------------------
    # é…ç½®å›æµ‹å‚æ•°ï¼ˆéœ€æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    # ----------------------
    NEW_CSV_PATH = "D:\lc\githubCode\DeepQuant\data\\000001_20250719_20250912.csv"  # æ–°æ•°æ®CSVè·¯å¾„ï¼ˆå¦‚8æœˆæ•°æ®ï¼‰
    MODEL_PATH = "D:\lc\githubCode\DeepQuant\output\\09151514\mlp_09151514_ep260_55.95.pth"  # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    SEQ_LEN = 20  # è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼ï¼‰
    THRESHOLD = 0.5  # æ¶¨è·Œåˆ¤æ–­é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰

    # ----------------------
    # æ­¥éª¤1ï¼šè¯»å–å¹¶é¢„å¤„ç†æ–°æ•°æ®
    # ----------------------
    print(f"ğŸ“Š è¯»å–æ–°æ•°æ®ï¼š{NEW_CSV_PATH}")
    df_new = read_stock_data(NEW_CSV_PATH)
    print(f"æ–°æ•°æ®æ€»è¡Œæ•°ï¼š{len(df_new)}")

    # ----------------------
    # æ­¥éª¤2ï¼šåˆ›å»ºæ–°æ•°æ®çš„Dataset
    # ----------------------
    print(f"\nğŸ“¦ åˆ›å»ºæ–°æ•°æ®æ•°æ®é›†ï¼ˆåºåˆ—é•¿åº¦ï¼š{SEQ_LEN}ï¼‰")
    test_dataset = StockDataset_binary(
        df=df_new,
        seq_len=SEQ_LEN,
        target='close',
        pred_horizon=1
    )
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°ï¼š{len(test_dataset)}")

    # ----------------------
    # æ­¥éª¤3ï¼šåˆå§‹åŒ–è®¾å¤‡å¹¶åŠ è½½æ¨¡å‹
    # ----------------------
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸ’» ä½¿ç”¨è®¾å¤‡ï¼š{device}")
    model = load_pretrained_model(
        model_path=MODEL_PATH,
        seq_len=SEQ_LEN,
        num_features=9,  # å›ºå®šä¸º5ä¸ªç‰¹å¾ï¼ˆOpen/High/Low/Close/Volumeï¼‰
        device=device
    )

    # ----------------------
    # æ­¥éª¤4ï¼šæ‰§è¡Œå›æµ‹å¹¶è®¡ç®—æŒ‡æ ‡
    # ----------------------
    print(f"\nğŸš€ å¼€å§‹å›æµ‹ï¼ˆé˜ˆå€¼ï¼š{THRESHOLD}ï¼‰")
    pred_probs, pred_labels, true_labels, metrics = backtest_model(
        model=model,
        test_dataset=test_dataset,
        device=device,
        threshold=THRESHOLD
    )

    # æ‰“å°å›æµ‹ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“ˆ å›æµ‹ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š{metrics['accuracy']:.2f}%")
    print(f"ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼š{metrics['precision']:.2f}%")  # é¢„æµ‹ä¸ºæ¶¨æ—¶ï¼Œå®é™…æ¶¨çš„æ¦‚ç‡
    print(f"å¬å›ç‡ï¼ˆRecallï¼‰ï¼š{metrics['recall']:.2f}%")  # å®é™…ä¸ºæ¶¨æ—¶ï¼Œè¢«é¢„æµ‹å¯¹çš„æ¦‚ç‡
    print(f"F1å€¼ï¼ˆF1-Scoreï¼‰ï¼š{metrics['f1_score']:.2f}%")  # ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
    print(f"é¢„æµ‹æ ·æœ¬æ€»æ•°ï¼š{len(true_labels)}")
    print(f"æ­£ç¡®é¢„æµ‹æ•°ï¼š{sum(pred_labels == true_labels)}")
    print(f"é”™è¯¯é¢„æµ‹æ•°ï¼š{sum(pred_labels != true_labels)}")
    print("=" * 60)

    # ----------------------
    # æ­¥éª¤5ï¼šç»˜åˆ¶å›æµ‹å¯è§†åŒ–å›¾
    # ----------------------
    print(f"\nğŸ“Š ç»˜åˆ¶å›æµ‹ç»“æœå›¾ï¼ˆæ˜¾ç¤ºæœ€å300ä¸ªç‚¹ï¼‰")
    plot_backtest_result(
        true_labels=true_labels,
        pred_labels=pred_labels,
        num_points=300  # å¯è°ƒæ•´æ˜¾ç¤ºçš„ç‚¹æ•°
    )

    # ----------------------
    # æ­¥éª¤6ï¼šï¼ˆå¯é€‰ï¼‰ä¿å­˜å›æµ‹ç»“æœåˆ°CSV
    # ----------------------
    save_result = input("\næ˜¯å¦ä¿å­˜å›æµ‹ç»“æœåˆ°CSVï¼Ÿï¼ˆy/nï¼‰ï¼š")
    if save_result.lower() == 'y':
        result_df = pd.DataFrame({
            "æ—¶é—´æ­¥": range(len(true_labels)),
            "çœŸå®æ ‡ç­¾": true_labels,
            "é¢„æµ‹æ ‡ç­¾": pred_labels,
            "é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡": pred_probs.round(4),
            "é¢„æµ‹æ˜¯å¦æ­£ç¡®": (pred_labels == true_labels).astype(int)
        })
        # ä¿å­˜è·¯å¾„ï¼ˆä¸æ¨¡å‹åŒç›®å½•ï¼‰
        save_path = MODEL_PATH.replace(".pth", "_backtest_result.csv")
        result_df.to_csv(save_path, index=False, encoding='utf-8-sig')
        print(f"âœ… å›æµ‹ç»“æœå·²ä¿å­˜åˆ°ï¼š{save_path}")
